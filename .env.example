# NFMR Environment Configuration
# Copy this file to .env and fill in your values

# =============================================================================
# LLM API Configuration
# =============================================================================

# OpenAI API (for GPT models)
OPENAI_API_KEY=your_openai_api_key_here

# HuggingFace (for Llama and other open models)
HUGGINGFACE_TOKEN=your_huggingface_token_here

# Anthropic API (for Claude models)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# =============================================================================
# Model Settings
# =============================================================================

# Default LLM model for RAG pipeline
DEFAULT_LLM_MODEL=meta-llama/Meta-Llama-3-8B-Instruct

# LLM generation temperature (0.0 for deterministic)
LLM_TEMPERATURE=0.0

# Maximum tokens to generate
LLM_MAX_TOKENS=512

# =============================================================================
# Evaluation Settings
# =============================================================================

# Timeout for forgetting operations (seconds)
BENCHMARK_TIMEOUT=300

# Maximum memory for forgetting operations (GB)
MAX_MEMORY_GB=9

# Number of runs per configuration
NUM_RUNS=100

# =============================================================================
# Paths (optional, defaults will be used if not set)
# =============================================================================

# Path to ontology files
# ONTOLOGY_PATH=data/ontologies/

# Path to benchmark datasets
# BENCHMARK_PATH=data/benchmarks/

# Output directory for results
# OUTPUT_PATH=results/

# =============================================================================
# Logging
# =============================================================================

# Log level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Log file path (optional)
# LOG_FILE=nfmr.log
